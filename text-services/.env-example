# Database URLs
MQ_URL=amqp://guest:guest@rabbitmq:5672//
REDIS_URL=redis://redis:6379/0

# RabbitMQ
RMQ_USER=guest
RMQ_PWD=guest

# Redis
REDIS_PWD=

# Directories
COMMON_DATA_DIR=/common_data
OUTPUT_DIR=/app/output

# LLM Provider Configuration
# Options: "ollama", "openai", "anthropic", "cohere", "gemini"
LLM_PROVIDER=ollama

# Ollama Configuration (for local models)
OLLAMA_HOST=http://host.docker.internal:11434
OLLAMA_MODEL=llama2

# OpenAI Configuration
OPENAI_API_KEY=
OPENAI_MODEL=gpt-3.5-turbo

# Anthropic Configuration
ANTHROPIC_API_KEY=
ANTHROPIC_MODEL=claude-3-haiku-20240307

# Cohere Configuration
# COHERE_API_KEY=your_cohere_api_key_here
# COHERE_MODEL=command

# Gemini Configuration
GEMINI_API_KEY=
GEMINI_MODEL=gemini-pro

# Task Configuration
LLM_REQUEST_TIMEOUT=60  # seconds
TASK_RETRY_COUNT=3
TASK_RETRY_BACKOFF=5  # seconds
